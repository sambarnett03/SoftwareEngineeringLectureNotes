## Lecture 7: Continuous Integration( CI)

- An automated process for verifying and integrating code changes.

- Objective: to detect and resolve issues early by frequently testing and integrating code changes. Cognitive overhead is much smaller by solving problems early while you still remember everything.

- Ensure compatability between mac, linux and windows.

- Avoiding dependencies on specific user data or development machine configurations e.g different versions of python, or hard code directory path for specific file you're using.


### Key principles
- Single source repo: maintain all code and dependencies in a shared repo - this is the gold standard repo with most recent updates.

- Automate the build: automatically compile, package and create installers for the code.

- Self-testing builds: automatically run unit tests on different versions of python and different os.

- Commit frequently: integrate changes regularly to avoid complex conflicts. Use issue/feature branch and main branch model.

- Integration machine: ensure builds and tests are conducted in a standardised, clean environment. Avoids dependency on e.g hard coded file path.

- Visibility and transparency: ensure all build and test results are accessible to the entire team.



### CI Tools
- We use GitHub Actions. If you have a public repo, you can use runners for every os on the cloud.

- Other options: GitLab, GitBucket, TravisCI, AppVeyor.


### GitHub actions
```{yaml}
name: Hello world

on:
    push:
    pull_request:
    workflow_dispatch:

jobs:
    basic-job:
        runs-on: ubuntu-latest

        steps:
        -   name: Run a one-line script
            run: echo 'hello world'
```

Here, the on: block tells you what will run when. Leaving empty means that the tests will run in every instance. workflow_dispatch enables the use of the githuib gui. Other triggers are possible eg. schedule .

runs-on is either windows, mac or ubuntu. The steps run specific commands - e.g python or pytest. First step is typically checkout the repo, the second install dependencies, and the third run pytest. Each step gets either a tick or cross depending on whether it worked or not.



## Notes from exercises
- To create a workflow, make a folder at 
```bash
.github/workflows   # in your root project directory
```

- Workflows are made as .yml files in this folder. e.g:
```yaml
name: Basic GitHub Actions Workflow

on:
  push:
  pull_request:
  workflow_dispatch:

jobs:
  basic-job:
    runs-on: ubuntu-latest

    steps:
      - name: Run a one-line script
        run: echo "Hello, world!"
```
- Breaking down this example:
    - on: block describes when the workflow should be run. An empty argument implies it should run on every instance of the case e.g every push. Additional arguments are e.g specific branch names. workflow-dispatch gives the option to run the test with the GUI

    - jobs: block gives the actual tests that will run.

    - the name argument in steps helps to quickly recognise which step failed.



- Basic templates can be searched for on GitHub. An example for running Python on various versions is below:

```yaml

name: Python package

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  workflow_dispatch:


jobs:
  build:

    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.9", "3.10", "3.11"]

    steps:
    - uses: actions/checkout@v4
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v3
      with:
        python-version: ${{ matrix.python-version }}
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip setuptools wheel
        python -m pip install .[dev]
    - name: Lint with flake8
      run: |
        # stop the build if there are Python syntax errors or undefined names
        flake8
    - name: Test with pytest
      run: |
        pytest

```

- Code breakdown:
    - fail-fast: if one version fails, the rest will continue to run
    - matrix: allows several versions to be ran at once. Could replace with os-version: [ubuntu-latest, macos-latest, windows-latest] to access os versions. 
    - The rest is kind of boiler plate - just copy and paste. The tests would typically be more complex than just pytest, see example later.



### Test coverage
- The extent to which the tests cover each line in your code can be found using pytest --cov. An example is:
```bash
pytest --cov-config=.coveragerc --cov=./ci_course --cov-report=xml
```
    - --cov-config=.coveragerc specific the config file for the coverage assessment. The autogenerated one simply has ignore files in the test folder.
    - --cov-./ci_course gives the folder to check the coverage of.
    - --cov-report.xml gives the type of output file. 

- Github actions can automate this by placing it inside a worfklow, which will be shown below.

- Codecov is website that allows you to easily view the output of such a coverage test, for all your github repos. To set up codecov:
    - sign in with github account
    - click configure next to your repository
    - use githubactions, pytest, and select repository token. 
    - navigate to repo in github, go to settings, secrets and variables, actions, new repository secret, then put 'CODECOV_TOKEN' as the name and the generated string from code_cov as the variable. 

- To automate the testing of coverage of a repo, add this to workflow

```yaml
# This workflow will install Python dependencies, run tests and lint with a variety of Python versions
# For more information see: https://docs.github.com/en/actions/automating-builds-and-tests/building-and-testing-python

name: Coverage Report
- name: Run coverage test
    run: |
    pytest --cov-config=.coveragerc --cov=./ci_course --cov-report=xml --cov-branch

- name: Upload coverage reports to Codecov
    uses: codecov/codecov-action@v5
    with:
    token: ${{ secrets.CODECOV_TOKEN }}
    fail_ci_if_error: true
    files: coverage.xml

```

- Codecov should now show the coverage - you can view it line by line. 



### Making Documentation
- We use sphinx and read the docs.

- Inside a venv, make a docs folder in the root of your project and type:
```bash
pip install sphinx
sphinx-quickstart
``` 

- Add a .gitkeep file inside the _static folder so it gets pushed correctly.

- Go to Read the Docs. 
    - login with github
    - import a project from your github
    - follow the instructions, leaving everything as default
    - this should build the website from the docs folder in the repo









