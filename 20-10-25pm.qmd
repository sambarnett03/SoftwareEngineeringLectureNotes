## Lecture 8: Packaging and Dependency Management

- Packages are a bundle of code, resources and metadata (e.g version of python needed etc), e.g numpy, pandas etc.


### Package Dependencies
- Software depends on other software.

- Packages define any that they rely on in metadata. 

- Dependencies are typically installed alongside the parent package.


### Package managers
- Almost every language has at least one.

- In python, pip and conda are good examples.

- These handle package install, upgrading and removing.

- They tend to manage dependencies automatically.

- They can try to solve dependencies automatically.


### Sharing packages
- Developers upload packages to online repositories, in Python this is PyPI - python package inventory.

- Package managers can search these repositories and download packages.



### Maintaing Python packages
- There are standard tools:
    - setuptools / wheel / twine are libraries that help
    - setup.py and setup.cfg - traditional building scripts (project info + dependencies)
    - pyproject.toml - modern standard for build requirements, simpler and more flexible than setup.py 
    - pip is standard package manager, supports both pyproject.toml and setup.py 
    - can use other tools on top of these fundamentals, e.g conda, uv etc. These don't provided added functionality, just make it easier. uv is best of these

- When building a package, you can either have a source distribution (sdists) or wheel distributions. sdists just uploads your original scripts to pypi. Wheel distributions allow you to package additional things as well, including compiled code e.g c++ with python wrapper. These wheels may be os specific. 

- Sharing a package - build, register on Test PyPI, upload via twine, test install.

- Usually never actually upload to PyPI from CLI, usually use GitHub Actions.


### Building a Python package
- Very specific structure.

- Base directory :
    - source code directory (whose name is name of package)
        - dunder init.py (two underscores either side). Can be empty, or can be used to give user specific access to certain functions and not to others
        - then sub folders, each with their own init.pys

    - metadata files (including pyproject.toml)
    - docs / tests folders
    - readme.md

- Typically you use a template when building a library, you rarely start from scratch. cookiecutter is a popular tool for generating project skeleton. However, typically introduce more functionality then necessary. uv offers good templates.



## Notes from excercises
- The _ _init__.py gives access to functions which can be accessed with dot notation. In the following example, users can access func1 and func2:
```{python}
#parent_directory/__init__.py
from .script1 import func1
from .script2 import func2
```

- A common error can occur when calling a package from a different folder: ModuleNotFoundError. This is usually because the package directory is not in the system path. A quick fix to this is:
```bash
import sys 
sys.path.append('path/to/folder')
```
- A better solution is to make the directory into a package using setuptools. It can then be pip installed into the virtual environment.


### Setup tools, config files and pip
- In order to create a package that can be pip installed, a pyproject.toml file is required. This contains some metadata about the package. An example is below:

```toml
[build-system]
requires = ["setuptools", "wheel"] # setuptools and wheel are necessary for the build

[project]
name = "tstools"
version = "0.1"
description = "A package to analyse timeseries"
authors = [
    {name = "Spam Eggs", email = "spam.eggs@email.com"}
]
readme = "README.md"
license = {text = "MIT"}
dependencies = ["numpy", "matplotlib", "scipy"]

[project.urls]
Source = "example.com"

[project.scripts] # Define scripts here if you have any

[project.optional-dependencies] # Define optional dependencies here if you have any
```

- The folder structure should look like:
    - mypackage_dist/
        - pyproject.toml
        - mypackage/
            - init
            - scripts
            - tests


- Now can pip install path/to/pyproject.toml

- You can pip install in editable mode, which means that changes in the package source code are automatically reflected by pip - you don't need to reinstall after every change:
```bash
# in directory to mypackage_dist/
pip install -e .
```


### Build, wheels and source distribution
- The build library allows you to easily prepare your project to be uploaded to PyPI:
```bash
pip install build wheel
python -m build --sdist     # builds a sdist 
python -m build --wheel     # builds a wheel
python -m build             # builds both
```

- sdists are sufficient for packages in pure python. 

- wheels are used when there is precompiled code as well as pure python.

- Both methods produce archive files (like zip and tar files), with the files in the original package plus some extra metadata.

- To install a wheel 
```bash
python -m pip install packageroot/dist/packagename*.whl
```

- Twine is used to publish packages to PyPI. 
```bash
pip install twine
twin upload path/to/.whl
```

- Repos can be uploaded to testpypi using
```bash
# run from within packagename_dist folder so dist can be seen
twine upload --repository testpypi dist/*
```